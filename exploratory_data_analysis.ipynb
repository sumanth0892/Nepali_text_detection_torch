{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2232601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import codecs\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65fda2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_char_list = 'charList.txt'\n",
    "hindi_vocab = 'hindi_vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb929b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('full.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [x.strip() for x in lines]\n",
    "chars = set()\n",
    "print(lines[:5])\n",
    "batchSize = 32\n",
    "img_size = (128, 32)\n",
    "max_text_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ddcd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, gt_text, file_path):\n",
    "        self.gt_text = gt_text\n",
    "        self.file_path = file_path\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    def __init__(self, gt_texts, imgs):\n",
    "        self.imgs = np.stack(imgs, axis = 0)\n",
    "        self.gt_texts = gt_texts\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, batch_size, img_size, max_text_len):\n",
    "        \"\"\"\n",
    "        Loader for the dataset\n",
    "        :param file_path: File path of the image\n",
    "        :param batch_size: Batch size\n",
    "        :param img_size: Size of the image\n",
    "        :param max_text_len: Maximum text length\n",
    "        \"\"\"\n",
    "        self.data_augmentation = False\n",
    "        self.cur_idx = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.samples = []\n",
    "\n",
    "        with codecs.open(\"full.txt\", 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [x.strip() for x in lines]\n",
    "        chars = set()\n",
    "        print(lines[5])\n",
    "        for line in lines:\n",
    "            if not line or line[0] == '#':\n",
    "                continue\n",
    "            line_split = line.strip().split(' ')\n",
    "            if line_split[0] == '\\ufeff':\n",
    "                continue\n",
    "            file_name = line_split[0]\n",
    "\n",
    "            # Ground Truth text starts at column 1\n",
    "            gt_text = self.truncate_label(' '.join(line_split[1]), max_text_len)\n",
    "            chars = chars.union(set(list(gt_text)))\n",
    "\n",
    "            # Check if image not empty\n",
    "            if not os.path.getsize(file_name):\n",
    "                continue\n",
    "            self.samples.append(Sample(gt_text, file_name)) # This can be a dictionary\n",
    "\n",
    "        # Split into training, validation and testing sets\n",
    "        n1, n2 = int(0.8*len(self.samples)), int(0.9*len(self.samples))\n",
    "        self.train_samples = self.samples[:n1]\n",
    "        self.validation_samples = self.samples[n1:n2]\n",
    "        self.test_samples = self.samples[n2:]\n",
    "\n",
    "        # Put words into lists\n",
    "        self.train_words = [x.gt_text for x in self.train_samples]\n",
    "        self.test_words = [x.gt_text for x in self.test_samples]\n",
    "        self.valid_words = [x.gt_text for x in self.validation_samples]\n",
    "\n",
    "        # Number of randomly chosen samples per epoch\n",
    "        self.num_train_samples_per_epoch = 10000\n",
    "\n",
    "        self.train_set()\n",
    "\n",
    "        # List of chars in the dataset\n",
    "        self.char_list = sorted(list(chars))\n",
    "\n",
    "    @staticmethod\n",
    "    def truncate_label(text, max_text_len):\n",
    "        cost = 0\n",
    "        for i in range(len(text)):\n",
    "            if i != 0 and text[i] == text[i - 1]:\n",
    "                cost += 2\n",
    "            else:\n",
    "                cost += 1\n",
    "            if cost > max_text_len:\n",
    "                return text[:i]\n",
    "        return text\n",
    "\n",
    "    def train_set(self):\n",
    "        \"\"\"\n",
    "        Switch to randomly chosen subset of training set\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.data_augmentation = True\n",
    "        self.cur_idx = 0\n",
    "        random.shuffle(self.train_samples)\n",
    "        self.samples = self.train_samples[:self.num_train_samples_per_epoch]\n",
    "\n",
    "    def validation_set(self):\n",
    "        \"\"\"\n",
    "        Switch to validation set\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.data_augmentation = False\n",
    "        self.cur_idx = 0\n",
    "        random.shuffle(self.validation_samples)\n",
    "        self.samples = self.validation_samples\n",
    "\n",
    "    def test_set(self):\n",
    "        \"\"\"\n",
    "        Switch to testing set\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.data_augmentation = False\n",
    "        self.cur_idx = 0\n",
    "        random.shuffle(self.test_samples)\n",
    "        self.samples = self.test_samples\n",
    "\n",
    "    def get_iterator_info(self):\n",
    "        \"\"\"\n",
    "        Current batch index and total number of batches\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.cur_idx // self.batch_size + 1, len(self.samples) // self.batch_size\n",
    "\n",
    "    def has_next(self):\n",
    "        return self.cur_idx + self.batch_size <= len(self.samples)\n",
    "\n",
    "    def get_next(self):\n",
    "        batch_range = range(self.cur_idx, self.cur_idx + self.batch_size)\n",
    "        gt_texts = [self.samples[i].gt_text for i in batch_range]\n",
    "        imgs = [preprocess(cv2.imread(self.samples[i].file_path, cv2.IMREAD_GRAYSCALE), self.img_size, self.data_augmentation) for i in batch_range]\n",
    "        self.cur_idx += self.batch_size\n",
    "        return Batch(gt_texts, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444db133",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(batchSize, img_size, max_text_len)\n",
    "print(len(dataloader.char_list))\n",
    "open(fn_char_list, 'w', encoding = 'utf-8').write(str().join(dataloader.char_list))\n",
    "open(hindi_vocab, 'w', encoding='UTF-8').write(str(' ').join(dataloader.train_words + dataloader.valid_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369aaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "BestPath = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa37bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 kernel",
   "language": "python",
   "name": "python310_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
